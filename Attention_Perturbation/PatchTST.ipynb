{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append('path/to/PatchTST/PatchTST_supervised')\n",
    "os.chdir('path/to/PatchTST/PatchTST_supervised')\n",
    "\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual, test_params_flop\n",
    "from utils.metrics import metric\n",
    "from data_provider.data_factory import data_provider\n",
    "from models import Informer, Autoformer, Transformer, DLinear, Linear, NLinear, PatchTST\n",
    "from models.PatchTST import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # load parameters\n",
    "        self.enc_in = 1\n",
    "        self.seq_len = 96\n",
    "        self.label_len = 0\n",
    "        self.pred_len = 96\n",
    "        self.e_layers = 6\n",
    "        self.n_heads = 16\n",
    "        self.d_model = 128\n",
    "        self.d_ff = 256\n",
    "        self.dropout = 0.2\n",
    "        self.fc_dropout = 0.2\n",
    "        self.head_dropout = 0.0\n",
    "        self.individual = False\n",
    "        self.patch_len = 16\n",
    "        self.stride = 8\n",
    "        self.padding_patch = 'end'\n",
    "        self.revin = True\n",
    "        self.affine = False\n",
    "        self.subtract_last = False\n",
    "        self.decomposition = False\n",
    "        self.kernel_size = 25\n",
    "\n",
    "        self.batch_size = 128\n",
    "        self.data = 'ETTh1'\n",
    "        self.embed = 'timeF'\n",
    "        self.freq = 'h'\n",
    "        self.root_path = 'path/to/PatchTST/PatchTST_supervised/dataset'\n",
    "        self.data_path = 'ETTh1.csv'\n",
    "        self.features = 'M'\n",
    "        self.target = 'OT'\n",
    "        self.num_workers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configs = {\n",
    "    'ETTm2': {'data':'ETTm2', 'data_path': 'path/to/PatchTST/PatchTST_supervised/dataset/'+'/ETT-small/ETTm2.csv', 'enc_in': 7},\n",
    "    'Electricity': {'data':'custom', 'data_path': 'path/to/PatchTST/PatchTST_supervised/dataset/'+'/electricity/electricity.csv', 'enc_in': 321},\n",
    "    'weather': {'data':'custom', 'data_path': 'path/to/PatchTST/PatchTST_supervised/dataset/'+'/weather/weather.csv', 'enc_in': 21},\n",
    "    'traffic': {'data':'custom', 'data_path': 'path/to/PatchTST/PatchTST_supervised/dataset/'+'/traffic/traffic.csv', 'enc_in': 862},\n",
    "    'Dataset_Patch_dependent': {'data':'Dataset_Patch_dependent', 'data_path': 'path/to/PatchTST/PatchTST_supervised/dataset/'+'/traffic/traffic.csv', 'enc_in': 1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "\n",
    "args.seq_len = 336\n",
    "args.stride = 16\n",
    "args.e_layers = 3\n",
    "dataset = 'ETTm2'\n",
    "model_path = 'path/to/checkpoint.pth'\n",
    "\n",
    "for attr in dataset_configs[dataset].keys():\n",
    "    value = dataset_configs[dataset][attr]\n",
    "    setattr(args, attr, value)\n",
    "\n",
    "train_data, train_loader = data_provider(args, flag='train')\n",
    "vali_data, vali_loader = data_provider(args, flag='val')\n",
    "test_data, test_loader = data_provider(args, flag='test')\n",
    "\n",
    "model = Model(args).to('cuda')\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.module\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "device = 'cuda'\n",
    "criterion = nn.MSELoss().to(device)\n",
    "total_loss = []\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(tqdm(test_loader)):\n",
    "    # for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(tqdm(train_loader)):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float()\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float().to(device)\n",
    "        batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "        outputs = model(batch_x)\n",
    "        outputs = outputs[:, -args.pred_len:, 0:]\n",
    "        batch_y = batch_y[:, -args.pred_len:, 0:].to(device)\n",
    "\n",
    "        pred = outputs.detach().cpu()\n",
    "        true = batch_y.detach().cpu()\n",
    "\n",
    "        loss = criterion(pred, true)\n",
    "\n",
    "        total_loss.append(loss)\n",
    "total_loss = np.average(total_loss)\n",
    "print('loss:', total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Perturbation Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_hooks():\n",
    "    global hooks\n",
    "    try:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def set_atten_hook(module, input, output):\n",
    "    global attenuation # 0.0 ~ 1.0\n",
    "    # # ZERO\n",
    "    # output = torch.zeros_like(output)\n",
    "    # # MEAN\n",
    "    # output = torch.zeros_like(output) + torch.mean(output, dim=-2, keepdim=True)\n",
    "    # # EYE\n",
    "    # eye = torch.eye(output.shape[2], device=output.device)\n",
    "    # output = eye.unsqueeze(0).unsqueeze(1).repeat(output.shape[0], output.shape[1], 1, 1)\n",
    "    return output * attenuation + torch.mean(output, dim=-1, keepdim=True) * ( 1 - attenuation )\n",
    "    # return output * attenuation\n",
    "\n",
    "def noise_score_hook(module, input):\n",
    "    global noise_score\n",
    "    noise = torch.randn_like(input[0]) * torch.std(input[0], dim=-1, keepdim=True) * noise_score\n",
    "    return (input[0] + noise,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_atten_blocks = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "delete_hooks()\n",
    "hooks = []\n",
    "block_idx = 0\n",
    "for layer in model.model.backbone.encoder.layers:\n",
    "    if block_idx in zero_atten_blocks:\n",
    "        hooks.append(layer.self_attn.sdp_attn.attn_dropout.register_forward_hook(set_atten_hook))\n",
    "        hooks.append(layer.self_attn.sdp_attn.softmax_layer.register_forward_pre_hook(noise_score_hook))\n",
    "    block_idx += 1\n",
    "\n",
    "attenuations = [i/10 for i in range(0, 11, 1)] # 0.0 ~ 1.0\n",
    "noise_scores = [i/10*2 for i in range(0, 11, 1)] # 0.0 ~ 2.0\n",
    "\n",
    "losses = np.zeros((len(attenuations), len(noise_scores)))\n",
    "\n",
    "for i_attenuation, attenuation in enumerate(attenuations):\n",
    "    for j_noise_score, noise_score in enumerate(noise_scores):\n",
    "        total_loss = []\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(device)\n",
    "                batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                outputs = outputs[:, -args.pred_len:, 0:]\n",
    "                batch_y = batch_y[:, -args.pred_len:, 0:].to(device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        print('attenuation:', attenuation, 'noise_score:', noise_score, 'loss:', total_loss)\n",
    "        losses[i_attenuation, j_noise_score] = total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "X, Y = np.meshgrid(noise_scores, attenuations)\n",
    "ax.plot_surface(X, Y, losses, rstride=1, cstride=1, cmap='rainbow')\n",
    "ax.set_xlabel('noise_score')\n",
    "ax.set_ylabel('attenuation')\n",
    "ax.set_zlabel('loss')\n",
    "ax.set_zlim(0.16, 0.18)\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()\n",
    "\n",
    "points_to_annotate = [(0,0), (0,len(noise_scores)-1), (len(attenuations)-1,0), (len(attenuations)-1,len(noise_scores)-1)]\n",
    "for point in points_to_annotate:\n",
    "    x, y = point\n",
    "    ax.text(noise_scores[y], attenuations[x], losses[x,y], f'{losses[x,y]:.3f}', color='black')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFN Perturbation Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_hooks():\n",
    "    global hooks\n",
    "    try:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def set_ffn_hook(module, input, output):\n",
    "    global attenuation # 0.0 ~ 1.0\n",
    "    return output * attenuation + torch.mean(output, dim=-1, keepdim=True) * ( 1 - attenuation )\n",
    "\n",
    "def noise_score_hook(module, input):\n",
    "    global noise_score\n",
    "    noise = torch.randn_like(input[0]) * torch.std(input[0], dim=-1, keepdim=True) * noise_score\n",
    "    return (input[0] + noise,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_ffn_blocks = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "delete_hooks()\n",
    "hooks = []\n",
    "block_idx = 0\n",
    "for layer in model.model.backbone.encoder.layers:\n",
    "    if block_idx in zero_ffn_blocks:\n",
    "        hooks.append(layer.ff.register_forward_hook(set_ffn_hook))\n",
    "        hooks.append(layer.ff[1].register_forward_pre_hook(noise_score_hook))\n",
    "    block_idx += 1\n",
    "\n",
    "attenuations = [i/10 for i in range(0, 11, 1)] # 0.0 ~ 1.0\n",
    "noise_scores = [i/10*2 for i in range(0, 11, 1)] # 0.0 ~ 2.0\n",
    "\n",
    "losses = np.zeros((len(attenuations), len(noise_scores)))\n",
    "\n",
    "for i_attenuation, attenuation in enumerate(attenuations):\n",
    "    for j_noise_score, noise_score in enumerate(noise_scores):\n",
    "        total_loss = []\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(device)\n",
    "                batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                outputs = outputs[:, -args.pred_len:, 0:]\n",
    "                batch_y = batch_y[:, -args.pred_len:, 0:].to(device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        print('attenuation:', attenuation, 'noise_score:', noise_score, 'loss:', total_loss)\n",
    "        losses[i_attenuation, j_noise_score] = total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "X, Y = np.meshgrid(noise_scores, attenuations)\n",
    "ax.plot_surface(X, Y, losses, rstride=1, cstride=1, cmap='rainbow')\n",
    "ax.set_xlabel('noise_score')\n",
    "ax.set_ylabel('attenuation')\n",
    "ax.set_zlabel('loss')\n",
    "ax.set_zlim(0.16, 0.18)\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()\n",
    "\n",
    "points_to_annotate = [(0,0), (0,len(noise_scores)-1), (len(attenuations)-1,0), (len(attenuations)-1,len(noise_scores)-1)]\n",
    "for point in points_to_annotate:\n",
    "    x, y = point\n",
    "    ax.text(noise_scores[y], attenuations[x], losses[x,y], f'{losses[x,y]:.3f}', color='black')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
